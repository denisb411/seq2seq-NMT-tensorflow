{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The helper file\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "CODES = {'<unk>': 0, '<s>': 1, '</s>': 2}\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load Dataset from File\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data\n",
    "\n",
    "def preprocess_and_save_data(source_path, target_path):\n",
    "    \"\"\"\n",
    "    Preprocess Text Data.  Save to to file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preprocess\n",
    "    source_text = load_data(source_path)\n",
    "    target_text = load_data(target_path)\n",
    "\n",
    "    source_text = source_text.lower()\n",
    "    target_text = target_text.lower()\n",
    "\n",
    "    source_vocab_to_int, source_int_to_vocab = create_lookup_tables(source_text)\n",
    "    \n",
    "    target_vocab_to_int, target_int_to_vocab = create_lookup_tables(target_text)\n",
    "    \n",
    "    source_text, target_text = text_to_ids(source_text, target_text, source_vocab_to_int, target_vocab_to_int)\n",
    "\n",
    "    # Save Data\n",
    "    pickle.dump((\n",
    "        (source_text, target_text),\n",
    "        (source_vocab_to_int, target_vocab_to_int),\n",
    "        (source_int_to_vocab, target_int_to_vocab)), open('preprocess.p', 'wb'))\n",
    "\n",
    "def load_preprocess():\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    return pickle.load(open('preprocess.p', mode='rb'))\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    \"\"\"\n",
    "    vocab = set(text.split())\n",
    "    vocab_to_int = copy.copy(CODES)\n",
    "    \n",
    "    for v_i, v in enumerate(vocab, len(CODES)):\n",
    "        vocab_to_int[v] = v_i\n",
    "\n",
    "    int_to_vocab = {v_i: v for v, v_i in vocab_to_int.items()}\n",
    "\n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "def save_params(params):\n",
    "    \"\"\"\n",
    "    Save parameters to file\n",
    "    \"\"\"\n",
    "    pickle.dump(params, open('params.p', 'wb'))\n",
    "\n",
    "def load_params():\n",
    "    \"\"\"\n",
    "    Load parameters from file\n",
    "    \"\"\"\n",
    "    return pickle.load(open('params.p', mode='rb'))\n",
    "\n",
    "def batch_data(source, target, batch_size):\n",
    "    \"\"\"\n",
    "    Batch source and target together\n",
    "    \"\"\"\n",
    "    for batch_i in range(0, len(source)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        source_batch = source[start_i:start_i + batch_size]\n",
    "        target_batch = target[start_i:start_i + batch_size]\n",
    "        yield np.array(pad_sentence_batch(source_batch)), np.array(pad_sentence_batch(target_batch))\n",
    "\n",
    "def pad_sentence_batch(sentence_batch):\n",
    "    \"\"\"\n",
    "    Pad sentence with </s> id\n",
    "    \"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [CODES['</s>']] * (max_sentence - len(sentence))\n",
    "            for sentence in sentence_batch]\n",
    "\n",
    "def text_to_ids(source_text, target_text, source_vocab_to_int, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Convert source and target text to proper word ids\n",
    "    :param source_text: String that contains all the source text.\n",
    "    :param target_text: String that contains all the target text.\n",
    "    :param source_vocab_to_int: Dictionary to go from the source words to an id\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :return: A tuple of lists (source_id_text, target_id_text)\n",
    "    \"\"\"\n",
    "    source_text_to_id = [[source_vocab_to_int[word] for word in line.split()] for line in source_text.split('\\n')]\n",
    "    target_text_to_id = [[target_vocab_to_int[word] for word in line.split()] for line in target_text.split('\\n')]\n",
    "    \n",
    "    return (source_text_to_id, target_text_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_path = 'data/small_vocab_fr'\n",
    "target_path = 'data/small_vocab_en'\n",
    "source_text = load_data(source_path)\n",
    "target_text = load_data(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess_and_save_data(source_path, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.4.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "assert LooseVersion(tf.__version__) in [LooseVersion('1.4.0')], 'This project requires TensorFlow version 1.5  You are using {}'.format(tf.__version__)\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), _ = load_preprocess()\n",
    "# pad_sentence_batch(source_int_text)\n",
    "source_vocab = len(source_vocab_to_int)\n",
    "target_vocab = len(target_vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2seqHyperparams(object):\n",
    "    def __init__(self, hidden_units=256, n_layers_enconder=2,\n",
    "                 n_layers_decoder=2, num_encoder_symbols=source_vocab, \n",
    "                 num_decoder_symbols=target_vocab, learning_rate=0.01,\n",
    "                 embedding_size=15, max_gradient_norm=5.0, dtype=tf.float32,\n",
    "                 epochs=1, dropout=0.2, forget_bias=1.0,\n",
    "                 use_beam_search=True, beam_width=10, length_penalty_weight=0.0,\n",
    "                 use_attention=True, learning_rate_decay=False, \n",
    "                 use_bidirectional_enconder=False):\n",
    "    \n",
    "        self.hidden_units = hidden_units\n",
    "        self.n_layers_enconder = n_layers_enconder\n",
    "        self.n_layers_decoder = n_layers_decoder\n",
    "        self.num_encoder_symbols = num_encoder_symbols\n",
    "        self.num_decoder_symbols = num_decoder_symbols\n",
    "        self.learning_rate = learning_rate\n",
    "        self.embedding_size = embedding_size\n",
    "        self.max_gradient_norm = max_gradient_norm\n",
    "        self.dtype = dtype\n",
    "        self.dropout = dropout\n",
    "        self.forget_bias = forget_bias\n",
    "        self.use_beam_search = use_beam_search\n",
    "        self.beam_width = beam_width\n",
    "        self.length_penalty_weight = length_penalty_weight\n",
    "        self.use_attention = use_attention\n",
    "        self.learning_rate_decay = learning_rate_decay\n",
    "        self.use_bidirectional_enconder = use_bidirectional_enconder\n",
    "\n",
    "\n",
    "        # Extra vocabulary symbols\n",
    "        unk = '<unk>'\n",
    "        sos = '<s>'\n",
    "        eos = '</s>' # also function as PAD\n",
    "        self.extra_tokens = [unk, sos, eos]\n",
    "        self.unk_token = self.extra_tokens.index(unk) #unk_token = 0\n",
    "        self.start_token = self.extra_tokens.index(sos) # start_token = 1\n",
    "        self.end_token = self.extra_tokens.index(eos)   # end_token = 2\n",
    "\n",
    "hparams = Seq2seqHyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "from tensorflow.contrib.rnn import MultiRNNCell\n",
    "from tensorflow import layers\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    \n",
    "    ### DEFINING PLACEHOLDERS ###\n",
    "\n",
    "    # encoder_inputs: [batch_size, max_time_steps]\n",
    "    encoder_inputs = tf.placeholder(dtype=tf.int32,\n",
    "                shape=(None, None), name='encoder_inputs')\n",
    "\n",
    "    # encoder_inputs_length: [batch_size]\n",
    "    encoder_inputs_length = tf.placeholder(\n",
    "                dtype=tf.int32, shape=(None,), name='encoder_inputs_length')\n",
    "\n",
    "    # get dynamic batch_size\n",
    "    batch_size = tf.shape(encoder_inputs)[0]\n",
    "\n",
    "    ### TRAIN MODE PLACEHOLDERS ###\n",
    "\n",
    "    # decoder_inputs: [batch_size, max_time_steps]\n",
    "    decoder_inputs = tf.placeholder(\n",
    "                    dtype=tf.int32, shape=(None, None), name='decoder_inputs')\n",
    "\n",
    "    # decoder_inputs_length: [batch_size]\n",
    "    decoder_inputs_length = tf.placeholder(\n",
    "                    dtype=tf.int32, shape=(None,), name='decoder_inputs_length')\n",
    "\n",
    "    decoder_start_token = tf.ones(\n",
    "                    shape=[batch_size, 1], dtype=tf.int32) * hparams.start_token\n",
    "    decoder_end_token = tf.ones(\n",
    "                    shape=[batch_size, 1], dtype=tf.int32) * hparams.end_token  \n",
    "\n",
    "\n",
    "    # decoder_inputs_train: [batch_size , max_time_steps + 1]\n",
    "    # insert sos symbol in front of each decoder input\n",
    "    decoder_inputs_train = tf.concat([decoder_start_token,\n",
    "                                          decoder_inputs], axis=1)\n",
    "\n",
    "    # decoder_inputs_length_train: [batch_size]\n",
    "    decoder_inputs_length_train = decoder_inputs_length + 1\n",
    "\n",
    "    # decoder_targets_train: [batch_size, max_time_steps + 1]\n",
    "    # insert eos symbol at the end of each decoder input\n",
    "    decoder_targets_train = tf.concat([decoder_inputs,\n",
    "                                           decoder_end_token], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with train_graph.as_default():\n",
    "    ## DEFINING ENCODER ##\n",
    "\n",
    "    encoder_embeddings = tf.Variable(tf.random_uniform([hparams.num_encoder_symbols, hparams.embedding_size], -1.0, 1.0),\n",
    "                                     dtype=hparams.dtype)\n",
    "\n",
    "    # Embedded_inputs: [batch_size, time_step, embedding_size]\n",
    "    encoder_inputs_embedded = tf.nn.embedding_lookup(\n",
    "        params=encoder_embeddings, ids=encoder_inputs)\n",
    "\n",
    "    if hparams.use_bidirectional_enconder:\n",
    "        \n",
    "        num_bi_layers = int(hparams.n_layers_enconder / 2)\n",
    "        num_residual_layers = hparams.n_layers_enconder - 1\n",
    "        num_bi_residual_layers = int(num_residual_layers / 2)\n",
    "        \n",
    "        print(num_bi_layers, num_residual_layers, num_bi_residual_layers)\n",
    "        \n",
    "        cell_list = []\n",
    "        for i in range(hparams.n_layers_enconder):\n",
    "            cell = tf.contrib.rnn.BasicLSTMCell(hparams.hidden_units, forget_bias=hparams.forget_bias)\n",
    "\n",
    "            if (i >= hparams.n_layers_enconder - num_residual_layers):\n",
    "                cell = tf.contrib.rnn.ResidualWrapper(cell, residual_fn=None)\n",
    "                if hparams.dropout > 0.0:\n",
    "                    cell = tf.contrib.rnn.DropoutWrapper(\n",
    "                        cell=cell, input_keep_prob=(1.0 - hparams.dropout))\n",
    "            \n",
    "            cell_list.append(cell)\n",
    "            \n",
    "        if len(cell_list) == 1:  # Single layer.\n",
    "            fw_cell = cell_list[0]\n",
    "            bw_cell = cell_list[0]\n",
    "        else:  # Multi layers\n",
    "            fw_cell = tf.contrib.rnn.MultiRNNCell(cell_list)\n",
    "            bw_cell = tf.contrib.rnn.MultiRNNCell(cell_list)\n",
    "\n",
    "        fw_cell = tf.contrib.rnn.BasicLSTMCell(hparams.n_layers_enconder)\n",
    "        bw_cell = tf.contrib.rnn.BasicLSTMCell(hparams.n_layers_enconder)\n",
    "\n",
    "        bi_outputs, bi_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "                                                        fw_cell,\n",
    "                                                        bw_cell,\n",
    "                                                        encoder_inputs_embedded,\n",
    "                                                        dtype=dtype,\n",
    "                                                        sequence_length=encoder_inputs_length,\n",
    "                                                        time_major=False,\n",
    "                                                        swap_memory=True)\n",
    "        print(bi_outputs, \"\\n\\n\", bi_state)\n",
    "\n",
    "        encoder_outputs, bi_encoder_state = tf.concat(bi_outputs, -1), bi_state\n",
    "        \n",
    "#         if num_bi_layers == 1:\n",
    "#             encoder_last_state = bi_encoder_state\n",
    "#         else:\n",
    "#             # alternatively concat forward and backward states\n",
    "#             encoder_state = []\n",
    "#             for layer_id in range(num_bi_layers):\n",
    "#                 encoder_state.append(bi_encoder_state[0][layer_id])  # forward\n",
    "#                 encoder_state.append(bi_encoder_state[1][layer_id])  # backward\n",
    "#             encoder_last_state = tuple(encoder_state)\n",
    "\n",
    "        encoder_state = bi_encoder_state\n",
    "        \n",
    "    else:\n",
    "        # Build RNN cell\n",
    "        cells = []\n",
    "        for _ in range(hparams.n_layers_enconder):\n",
    "            cell = tf.contrib.rnn.BasicLSTMCell(hparams.hidden_units, forget_bias=hparams.forget_bias)\n",
    "            if hparams.dropout > 0.0:\n",
    "                cell = tf.contrib.rnn.DropoutWrapper(\n",
    "                    cell=cell, input_keep_prob=(1.0 - hparams.dropout))\n",
    "            cells.append(cell)\n",
    "        if hparams.n_layers_enconder == 1:\n",
    "            encoder_cells = cells[0]\n",
    "        else:\n",
    "            encoder_cells = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "\n",
    "        encoder_outputs, encoder_last_state = tf.nn.dynamic_rnn(\n",
    "            cell=encoder_cells, inputs=encoder_inputs_embedded,\n",
    "            sequence_length=encoder_inputs_length, dtype=hparams.dtype,\n",
    "            time_major=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with train_graph.as_default():\n",
    "    ### DEFINING DECODER ###\n",
    "\n",
    "    # Building decoder_cell\n",
    "    cells = []\n",
    "    # Build RNN cell\n",
    "    for _ in range(hparams.n_layers_decoder):\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(hparams.hidden_units, forget_bias=hparams.forget_bias)\n",
    "        if hparams.dropout > 0.0:\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(\n",
    "                cell=cell, input_keep_prob=(1.0 - hparams.dropout))\n",
    "        cells.append(cell)\n",
    "    if hparams.n_layers_decoder == 1:\n",
    "        decoder_cells = cells[0]\n",
    "    else:\n",
    "        decoder_cells = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "\n",
    "    if hparams.use_attention:\n",
    "        memory = encoder_outputs\n",
    "        \n",
    "        attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "            hparams.hidden_units,\n",
    "            memory,\n",
    "            memory_sequence_length=encoder_inputs_length,\n",
    "            normalize=True)\n",
    "        \n",
    "        decoder_cells_train = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            decoder_cells,\n",
    "            attention_mechanism,\n",
    "            attention_layer_size=hparams.hidden_units,\n",
    "            alignment_history=False,\n",
    "            output_attention=True,\n",
    "            name=\"attention\")\n",
    "        \n",
    "        decoder_initial_state = decoder_cells_train.zero_state(batch_size, hparams.dtype).clone(\n",
    "          cell_state=encoder_last_state)\n",
    "        \n",
    "    else:\n",
    "        decoder_cells_train = decoder_cells\n",
    "        decoder_initial_state = encoder_last_state\n",
    "\n",
    "    decoder_embeddings = tf.Variable(tf.random_uniform([hparams.num_decoder_symbols, hparams.embedding_size], -1.0, 1.0), dtype=hparams.dtype)\n",
    "    \n",
    "    # decoder_inputs_embedded: [batch_size, max_time_step + 1, embedding_size]\n",
    "    decoder_inputs_embedded = tf.nn.embedding_lookup(\n",
    "        params=decoder_embeddings, ids=decoder_inputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with train_graph.as_default():\n",
    "    ### TRAIN MODE ###\n",
    "    \n",
    "    # Helper to feed inputs for training: read inputs from dense ground truth vectors\n",
    "    training_helper = seq2seq.TrainingHelper(inputs=decoder_inputs_embedded,\n",
    "                                       sequence_length=decoder_inputs_length_train,\n",
    "                                       time_major=False,\n",
    "                                        name='training_helper')\n",
    "\n",
    "    training_decoder = seq2seq.BasicDecoder(cell=decoder_cells_train,\n",
    "                                       helper=training_helper,\n",
    "                                       initial_state=decoder_initial_state)\n",
    "\n",
    "    # decoder_outputs_train: BasicDecoderOutput\n",
    "    #                        namedtuple(rnn_outputs, sample_id)\n",
    "    # decoder_outputs_train.rnn_output: [batch_size, max_time_step + 1, num_decoder_symbols] if output_time_major=False\n",
    "    #                                   [max_time_step + 1, batch_size, num_decoder_symbols] if output_time_major=True\n",
    "    # decoder_outputs_train.sample_id: [batch_size], tf.int32\n",
    "    (decoder_outputs_train, decoder_last_state_train, \n",
    "         decoder_outputs_length_decode)  = seq2seq.dynamic_decode(decoder=training_decoder,\n",
    "                                                        output_time_major=False,\n",
    "                                                        swap_memory=True,\n",
    "                                                        impute_finished=True)\n",
    "\n",
    "    # More efficient to do the projection on the batch-time-concatenated tensor\n",
    "    # logits_train: [batch_size, max_time_step + 1, num_decoder_symbols]\n",
    "    \n",
    "    sample_id = decoder_outputs_train.sample_id\n",
    "    \n",
    "    output_layer = layers.Dense(hparams.num_decoder_symbols, name='output_projection')\n",
    "    logits_train = output_layer(decoder_outputs_train.rnn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with train_graph.as_default():\n",
    "    \n",
    "    ### LOSS, GRADIEND AND OPTIMIZATION ###\n",
    "    \n",
    "    if hparams.learning_rate_decay:\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "        learning_rate = tf.constant(hparams.learning_rate)\n",
    "\n",
    "        #using luong10 decay scheme\n",
    "        decay_factor = 0.5\n",
    "        start_decay_step = int(hparams.epochs / 2)\n",
    "        decay_times = 10\n",
    "\n",
    "        remain_steps = hparams.epochs - start_decay_step\n",
    "        decay_steps = int(remain_steps / decay_times)\n",
    "\n",
    "        learning_rate = tf.cond(global_step < start_decay_step,\n",
    "                                lambda: hparams.learning_rate,\n",
    "                                lambda: tf.train.exponential_decay(\n",
    "                                    hparams.learning_rate,\n",
    "                                    (global_step - start_decay_step),\n",
    "                                    decay_steps, decay_factor, staircase=True),\n",
    "                                name=\"learning_rate_decay_cond\")\n",
    "    \n",
    "    # Maximum decoder time_steps in current batch\n",
    "    max_decoder_length = tf.reduce_max(decoder_inputs_length_train)\n",
    "    \n",
    "    # masks: masking for valid and padded time steps, [batch_size, max_time_step + 1]\n",
    "    target_weights = tf.sequence_mask(lengths=decoder_inputs_length_train, \n",
    "                             maxlen=max_decoder_length, dtype=hparams.dtype, name='masks')\n",
    "    \n",
    "    crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=decoder_targets_train, logits=logits_train)\n",
    "    \n",
    "    loss = (tf.reduce_sum(crossent * target_weights) /\n",
    "        tf.cast(batch_size, dtype=hparams.dtype))\n",
    "\n",
    "    trainable_params = tf.trainable_variables()\n",
    "    \n",
    "    opt = tf.train.AdamOptimizer(learning_rate=hparams.learning_rate)\n",
    "    \n",
    "    gradients = tf.gradients(loss, \n",
    "                             trainable_params)\n",
    "    \n",
    "    clip_gradients, gradient_norm = tf.clip_by_global_norm(gradients, hparams.max_gradient_norm)\n",
    "    \n",
    "    updates = opt.apply_gradients(\n",
    "            zip(clip_gradients, trainable_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with train_graph.as_default():\n",
    "\n",
    "    ### INFERENCE MODE ###\n",
    "    start_tokens = tf.fill([batch_size], hparams.start_token)\n",
    "    \n",
    "    decoder_initial_state_infer = tf.contrib.seq2seq.tile_batch(\n",
    "                  encoder_last_state, multiplier=hparams.beam_width)\n",
    "    \n",
    "    if hparams.use_attention:\n",
    "        memory = tf.contrib.seq2seq.tile_batch(\n",
    "          memory, multiplier=hparams.beam_width)\n",
    "        \n",
    "        source_sequence_length = tf.contrib.seq2seq.tile_batch(\n",
    "          encoder_inputs_length, multiplier=hparams.beam_width)\n",
    "        \n",
    "        encoder_last_state = tf.contrib.seq2seq.tile_batch(\n",
    "          encoder_last_state, multiplier=hparams.beam_width)\n",
    "        \n",
    "        batch_size = batch_size * hparams.beam_width\n",
    "        \n",
    "        attention_mechanism_infer = tf.contrib.seq2seq.BahdanauAttention(\n",
    "            hparams.hidden_units,\n",
    "            memory,\n",
    "            memory_sequence_length=source_sequence_length,\n",
    "            normalize=True)\n",
    "        \n",
    "        decoder_cells_infer = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            decoder_cells,\n",
    "            attention_mechanism_infer,\n",
    "            attention_layer_size=hparams.hidden_units,\n",
    "            alignment_history=False,\n",
    "            output_attention=True,\n",
    "            name=\"attention_infer\")\n",
    "        \n",
    "        decoder_initial_state_infer = decoder_cells_infer.zero_state(batch_size, hparams.dtype).clone(\n",
    "          cell_state=encoder_last_state)\n",
    "    \n",
    "    if hparams.use_beam_search:\n",
    "\n",
    "        inference_decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "              cell=decoder_cells_infer,\n",
    "              embedding=decoder_embeddings,\n",
    "              start_tokens=start_tokens,\n",
    "              end_token=hparams.end_token,\n",
    "              initial_state=decoder_initial_state_infer,\n",
    "              beam_width=hparams.beam_width,\n",
    "              output_layer=output_layer,\n",
    "              length_penalty_weight=hparams.length_penalty_weight)\n",
    "        \n",
    "    else:\n",
    "        inference_helper = seq2seq.GreedyEmbeddingHelper(decoder_embeddings,\n",
    "                                                        start_tokens=start_tokens,\n",
    "                                                        end_token=hparams.end_token)\n",
    "\n",
    "        inference_decoder = seq2seq.BasicDecoder(cell=decoder_cells_infer,\n",
    "                                                 helper=inference_helper,\n",
    "                                                 initial_state=decoder_initial_state,\n",
    "                                                 output_layer=output_layer)\n",
    "    \n",
    "    maximum_iterations = tf.round(tf.reduce_max(encoder_inputs_length) * 2)\n",
    "    \n",
    "    (decoder_infer_outputs, decoder_infer_last_state,\n",
    "                 decoder_infer_outputs_length) = (seq2seq.dynamic_decode(\n",
    "                    decoder=inference_decoder,\n",
    "                    output_time_major=False,\n",
    "                    maximum_iterations=maximum_iterations))\n",
    "    \n",
    "    if hparams.use_beam_search:\n",
    "        decoder_pred_decode = decoder_infer_outputs.predicted_ids\n",
    "        tf.identity(decoder_pred_decode, 'decoder_pred_decode')\n",
    "    \n",
    "    else:\n",
    "        logits_infer = decoder_infer_outputs.rnn_output\n",
    "        sample_id_infer = decoder_infer_outputs.sample_id                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training parameters\n",
    "class TrainingHyperparams(object):\n",
    "    def __init__(self, epochs=1, batch_size=256):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "train_hparams = TrainingHyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch    0/538, Loss: 97.849\n",
      "Epoch   0 Batch    1/538, Loss: 75.930\n",
      "Epoch   0 Batch    2/538, Loss: 110.631\n",
      "Epoch   0 Batch    3/538, Loss: 100.326\n",
      "Epoch   0 Batch    4/538, Loss: 96.568\n",
      "Epoch   0 Batch    5/538, Loss: 162.645\n",
      "Epoch   0 Batch    6/538, Loss: 104.479\n",
      "Epoch   0 Batch    7/538, Loss: 90.449\n",
      "Epoch   0 Batch    8/538, Loss: 73.665\n",
      "Epoch   0 Batch    9/538, Loss: 72.432\n",
      "Epoch   0 Batch   10/538, Loss: 64.817\n",
      "Epoch   0 Batch   11/538, Loss: 63.512\n",
      "Epoch   0 Batch   12/538, Loss: 60.624\n",
      "Epoch   0 Batch   13/538, Loss: 60.704\n",
      "Epoch   0 Batch   14/538, Loss: 58.045\n",
      "Epoch   0 Batch   15/538, Loss: 57.687\n",
      "Epoch   0 Batch   16/538, Loss: 56.123\n",
      "Epoch   0 Batch   17/538, Loss: 54.575\n",
      "Epoch   0 Batch   18/538, Loss: 51.930\n",
      "Epoch   0 Batch   19/538, Loss: 52.913\n",
      "Epoch   0 Batch   20/538, Loss: 52.344\n",
      "Epoch   0 Batch   21/538, Loss: 50.336\n",
      "Epoch   0 Batch   22/538, Loss: 52.325\n",
      "Epoch   0 Batch   23/538, Loss: 48.683\n",
      "Epoch   0 Batch   24/538, Loss: 50.575\n",
      "Epoch   0 Batch   25/538, Loss: 50.875\n",
      "Epoch   0 Batch   26/538, Loss: 45.837\n",
      "Epoch   0 Batch   27/538, Loss: 44.948\n",
      "Epoch   0 Batch   28/538, Loss: 44.004\n",
      "Epoch   0 Batch   29/538, Loss: 43.370\n",
      "Epoch   0 Batch   30/538, Loss: 40.762\n",
      "Epoch   0 Batch   31/538, Loss: 39.054\n",
      "Epoch   0 Batch   32/538, Loss: 36.751\n",
      "Epoch   0 Batch   33/538, Loss: 35.775\n",
      "Epoch   0 Batch   34/538, Loss: 34.167\n",
      "Epoch   0 Batch   35/538, Loss: 31.768\n",
      "Epoch   0 Batch   36/538, Loss: 33.362\n",
      "Epoch   0 Batch   37/538, Loss: 30.407\n",
      "Epoch   0 Batch   38/538, Loss: 27.650\n",
      "Epoch   0 Batch   39/538, Loss: 26.216\n",
      "Epoch   0 Batch   40/538, Loss: 27.178\n",
      "Epoch   0 Batch   41/538, Loss: 26.099\n",
      "Epoch   0 Batch   42/538, Loss: 23.593\n",
      "Epoch   0 Batch   43/538, Loss: 22.405\n",
      "Epoch   0 Batch   44/538, Loss: 22.477\n",
      "Epoch   0 Batch   45/538, Loss: 21.755\n",
      "Epoch   0 Batch   46/538, Loss: 21.206\n",
      "Epoch   0 Batch   47/538, Loss: 19.990\n",
      "Epoch   0 Batch   48/538, Loss: 19.898\n",
      "Epoch   0 Batch   49/538, Loss: 20.432\n",
      "Epoch   0 Batch   50/538, Loss: 19.394\n",
      "Epoch   0 Batch   51/538, Loss: 18.722\n",
      "Epoch   0 Batch   52/538, Loss: 17.777\n",
      "Epoch   0 Batch   53/538, Loss: 18.424\n",
      "Epoch   0 Batch   54/538, Loss: 18.807\n",
      "Epoch   0 Batch   55/538, Loss: 19.367\n",
      "Epoch   0 Batch   56/538, Loss: 18.266\n",
      "Epoch   0 Batch   57/538, Loss: 18.258\n",
      "Epoch   0 Batch   58/538, Loss: 18.455\n",
      "Epoch   0 Batch   59/538, Loss: 17.080\n",
      "Epoch   0 Batch   60/538, Loss: 17.135\n",
      "Epoch   0 Batch   61/538, Loss: 16.237\n",
      "Epoch   0 Batch   62/538, Loss: 16.107\n",
      "Epoch   0 Batch   63/538, Loss: 15.630\n",
      "Epoch   0 Batch   64/538, Loss: 15.951\n",
      "Epoch   0 Batch   65/538, Loss: 15.429\n",
      "Epoch   0 Batch   66/538, Loss: 15.597\n",
      "Epoch   0 Batch   67/538, Loss: 15.143\n",
      "Epoch   0 Batch   68/538, Loss: 14.783\n",
      "Epoch   0 Batch   69/538, Loss: 14.795\n",
      "Epoch   0 Batch   70/538, Loss: 14.778\n",
      "Epoch   0 Batch   71/538, Loss: 14.448\n",
      "Epoch   0 Batch   72/538, Loss: 14.750\n",
      "Epoch   0 Batch   73/538, Loss: 14.913\n",
      "Epoch   0 Batch   74/538, Loss: 14.082\n",
      "Epoch   0 Batch   75/538, Loss: 14.672\n",
      "Epoch   0 Batch   76/538, Loss: 13.756\n",
      "Epoch   0 Batch   77/538, Loss: 13.972\n",
      "Epoch   0 Batch   78/538, Loss: 13.622\n",
      "Epoch   0 Batch   79/538, Loss: 13.663\n",
      "Epoch   0 Batch   80/538, Loss: 13.166\n",
      "Epoch   0 Batch   81/538, Loss: 13.619\n",
      "Epoch   0 Batch   82/538, Loss: 13.760\n",
      "Epoch   0 Batch   83/538, Loss: 13.389\n",
      "Epoch   0 Batch   84/538, Loss: 13.426\n",
      "Epoch   0 Batch   85/538, Loss: 13.431\n",
      "Epoch   0 Batch   86/538, Loss: 13.386\n",
      "Epoch   0 Batch   87/538, Loss: 13.895\n",
      "Epoch   0 Batch   88/538, Loss: 13.452\n",
      "Epoch   0 Batch   89/538, Loss: 13.154\n",
      "Epoch   0 Batch   90/538, Loss: 12.869\n",
      "Epoch   0 Batch   91/538, Loss: 13.163\n",
      "Epoch   0 Batch   92/538, Loss: 12.490\n",
      "Epoch   0 Batch   93/538, Loss: 12.655\n",
      "Epoch   0 Batch   94/538, Loss: 12.392\n",
      "Epoch   0 Batch   95/538, Loss: 12.360\n",
      "Epoch   0 Batch   96/538, Loss: 12.744\n",
      "Epoch   0 Batch   97/538, Loss: 12.051\n",
      "Epoch   0 Batch   98/538, Loss: 12.317\n",
      "Epoch   0 Batch   99/538, Loss: 12.041\n",
      "Epoch   0 Batch  100/538, Loss: 12.346\n",
      "Epoch   0 Batch  101/538, Loss: 11.834\n",
      "Epoch   0 Batch  102/538, Loss: 11.819\n",
      "Epoch   0 Batch  103/538, Loss: 11.891\n",
      "Epoch   0 Batch  104/538, Loss: 12.143\n",
      "Epoch   0 Batch  105/538, Loss: 11.636\n",
      "Epoch   0 Batch  106/538, Loss: 11.359\n",
      "Epoch   0 Batch  107/538, Loss: 11.322\n",
      "Epoch   0 Batch  108/538, Loss: 11.208\n",
      "Epoch   0 Batch  109/538, Loss: 11.645\n",
      "Epoch   0 Batch  110/538, Loss: 10.901\n",
      "Epoch   0 Batch  111/538, Loss: 10.889\n",
      "Epoch   0 Batch  112/538, Loss: 11.419\n",
      "Epoch   0 Batch  113/538, Loss: 11.573\n",
      "Epoch   0 Batch  114/538, Loss: 10.902\n",
      "Epoch   0 Batch  115/538, Loss: 10.908\n",
      "Epoch   0 Batch  116/538, Loss: 10.811\n",
      "Epoch   0 Batch  117/538, Loss: 11.180\n",
      "Epoch   0 Batch  118/538, Loss: 10.857\n",
      "Epoch   0 Batch  119/538, Loss: 10.309\n",
      "Epoch   0 Batch  120/538, Loss: 10.215\n",
      "Epoch   0 Batch  121/538, Loss: 10.069\n",
      "Epoch   0 Batch  122/538, Loss: 10.639\n",
      "Epoch   0 Batch  123/538, Loss: 10.330\n",
      "Epoch   0 Batch  124/538, Loss:  9.910\n",
      "Epoch   0 Batch  125/538, Loss:  9.720\n",
      "Epoch   0 Batch  126/538, Loss:  9.969\n",
      "Epoch   0 Batch  127/538, Loss:  9.935\n",
      "Epoch   0 Batch  128/538, Loss: 10.094\n",
      "Epoch   0 Batch  129/538, Loss:  9.932\n",
      "Epoch   0 Batch  130/538, Loss:  9.485\n",
      "Epoch   0 Batch  131/538, Loss:  9.935\n",
      "Epoch   0 Batch  132/538, Loss:  9.192\n",
      "Epoch   0 Batch  133/538, Loss:  9.352\n",
      "Epoch   0 Batch  134/538, Loss:  9.659\n",
      "Epoch   0 Batch  135/538, Loss:  9.396\n",
      "Epoch   0 Batch  136/538, Loss:  9.350\n",
      "Epoch   0 Batch  137/538, Loss:  9.157\n",
      "Epoch   0 Batch  138/538, Loss:  8.846\n",
      "Epoch   0 Batch  139/538, Loss:  9.147\n",
      "Epoch   0 Batch  140/538, Loss:  8.842\n",
      "Epoch   0 Batch  141/538, Loss:  8.984\n",
      "Epoch   0 Batch  142/538, Loss:  8.695\n",
      "Epoch   0 Batch  143/538, Loss:  8.893\n",
      "Epoch   0 Batch  144/538, Loss:  8.297\n",
      "Epoch   0 Batch  145/538, Loss:  8.300\n",
      "Epoch   0 Batch  146/538, Loss:  8.281\n",
      "Epoch   0 Batch  147/538, Loss:  7.918\n",
      "Epoch   0 Batch  148/538, Loss:  7.812\n",
      "Epoch   0 Batch  149/538, Loss:  7.921\n",
      "Epoch   0 Batch  150/538, Loss:  7.521\n",
      "Epoch   0 Batch  151/538, Loss:  7.246\n",
      "Epoch   0 Batch  152/538, Loss:  7.028\n",
      "Epoch   0 Batch  153/538, Loss:  6.862\n",
      "Epoch   0 Batch  154/538, Loss:  7.119\n",
      "Epoch   0 Batch  155/538, Loss:  6.613\n",
      "Epoch   0 Batch  156/538, Loss:  6.744\n",
      "Epoch   0 Batch  157/538, Loss:  5.934\n",
      "Epoch   0 Batch  158/538, Loss:  6.045\n",
      "Epoch   0 Batch  159/538, Loss:  5.981\n",
      "Epoch   0 Batch  160/538, Loss:  5.899\n",
      "Epoch   0 Batch  161/538, Loss:  5.771\n",
      "Epoch   0 Batch  162/538, Loss:  5.794\n",
      "Epoch   0 Batch  163/538, Loss:  5.418\n",
      "Epoch   0 Batch  164/538, Loss:  5.254\n",
      "Epoch   0 Batch  165/538, Loss:  5.150\n",
      "Epoch   0 Batch  166/538, Loss:  5.123\n",
      "Epoch   0 Batch  167/538, Loss:  4.974\n",
      "Epoch   0 Batch  168/538, Loss:  4.818\n",
      "Epoch   0 Batch  169/538, Loss:  4.832\n",
      "Epoch   0 Batch  170/538, Loss:  4.283\n",
      "Epoch   0 Batch  171/538, Loss:  4.232\n",
      "Epoch   0 Batch  172/538, Loss:  3.730\n",
      "Epoch   0 Batch  173/538, Loss:  4.088\n",
      "Epoch   0 Batch  174/538, Loss:  3.507\n",
      "Epoch   0 Batch  175/538, Loss:  3.712\n",
      "Epoch   0 Batch  176/538, Loss:  3.296\n",
      "Epoch   0 Batch  177/538, Loss:  3.292\n",
      "Epoch   0 Batch  178/538, Loss:  3.249\n",
      "Epoch   0 Batch  179/538, Loss:  3.313\n",
      "Epoch   0 Batch  180/538, Loss:  3.108\n",
      "Epoch   0 Batch  181/538, Loss:  3.172\n",
      "Epoch   0 Batch  182/538, Loss:  3.226\n",
      "Epoch   0 Batch  183/538, Loss:  2.808\n",
      "Epoch   0 Batch  184/538, Loss:  2.581\n",
      "Epoch   0 Batch  185/538, Loss:  2.472\n",
      "Epoch   0 Batch  186/538, Loss:  2.637\n",
      "Epoch   0 Batch  187/538, Loss:  2.330\n",
      "Epoch   0 Batch  188/538, Loss:  2.567\n",
      "Epoch   0 Batch  189/538, Loss:  2.221\n",
      "Epoch   0 Batch  190/538, Loss:  2.618\n",
      "Epoch   0 Batch  191/538, Loss:  2.533\n",
      "Epoch   0 Batch  192/538, Loss:  2.143\n",
      "Epoch   0 Batch  193/538, Loss:  1.975\n",
      "Epoch   0 Batch  194/538, Loss:  2.296\n",
      "Epoch   0 Batch  195/538, Loss:  2.102\n",
      "Epoch   0 Batch  196/538, Loss:  2.153\n",
      "Epoch   0 Batch  197/538, Loss:  1.765\n",
      "Epoch   0 Batch  198/538, Loss:  2.034\n",
      "Epoch   0 Batch  199/538, Loss:  1.877\n",
      "Epoch   0 Batch  200/538, Loss:  1.893\n",
      "Epoch   0 Batch  201/538, Loss:  1.721\n",
      "Epoch   0 Batch  202/538, Loss:  1.787\n",
      "Epoch   0 Batch  203/538, Loss:  2.091\n",
      "Epoch   0 Batch  204/538, Loss:  1.744\n",
      "Epoch   0 Batch  205/538, Loss:  2.008\n",
      "Epoch   0 Batch  206/538, Loss:  2.077\n",
      "Epoch   0 Batch  207/538, Loss:  1.849\n",
      "Epoch   0 Batch  208/538, Loss:  2.322\n",
      "Epoch   0 Batch  209/538, Loss:  2.002\n",
      "Epoch   0 Batch  210/538, Loss:  1.651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch  211/538, Loss:  1.775\n",
      "Epoch   0 Batch  212/538, Loss:  1.986\n",
      "Epoch   0 Batch  213/538, Loss:  1.705\n",
      "Epoch   0 Batch  214/538, Loss:  1.598\n",
      "Epoch   0 Batch  215/538, Loss:  1.541\n",
      "Epoch   0 Batch  216/538, Loss:  1.579\n",
      "Epoch   0 Batch  217/538, Loss:  1.536\n",
      "Epoch   0 Batch  218/538, Loss:  1.518\n",
      "Epoch   0 Batch  219/538, Loss:  1.316\n",
      "Epoch   0 Batch  220/538, Loss:  1.928\n",
      "Epoch   0 Batch  221/538, Loss:  1.694\n",
      "Epoch   0 Batch  222/538, Loss:  1.607\n",
      "Epoch   0 Batch  223/538, Loss:  1.475\n",
      "Epoch   0 Batch  224/538, Loss:  1.717\n",
      "Epoch   0 Batch  225/538, Loss:  1.568\n",
      "Epoch   0 Batch  226/538, Loss:  1.737\n",
      "Epoch   0 Batch  227/538, Loss:  1.378\n",
      "Epoch   0 Batch  228/538, Loss:  1.556\n",
      "Epoch   0 Batch  229/538, Loss:  1.365\n",
      "Epoch   0 Batch  230/538, Loss:  1.461\n",
      "Epoch   0 Batch  231/538, Loss:  1.407\n",
      "Epoch   0 Batch  232/538, Loss:  1.348\n",
      "Epoch   0 Batch  233/538, Loss:  1.505\n",
      "Epoch   0 Batch  234/538, Loss:  1.574\n",
      "Epoch   0 Batch  235/538, Loss:  1.409\n",
      "Epoch   0 Batch  236/538, Loss:  1.318\n",
      "Epoch   0 Batch  237/538, Loss:  1.253\n",
      "Epoch   0 Batch  238/538, Loss:  1.197\n",
      "Epoch   0 Batch  239/538, Loss:  1.381\n",
      "Epoch   0 Batch  240/538, Loss:  1.296\n",
      "Epoch   0 Batch  241/538, Loss:  1.706\n",
      "Epoch   0 Batch  242/538, Loss:  1.332\n",
      "Epoch   0 Batch  243/538, Loss:  1.321\n",
      "Epoch   0 Batch  244/538, Loss:  1.691\n",
      "Epoch   0 Batch  245/538, Loss:  1.205\n",
      "Epoch   0 Batch  246/538, Loss:  1.531\n",
      "Epoch   0 Batch  247/538, Loss:  1.286\n",
      "Epoch   0 Batch  248/538, Loss:  1.431\n",
      "Epoch   0 Batch  249/538, Loss:  1.154\n",
      "Epoch   0 Batch  250/538, Loss:  1.096\n",
      "Epoch   0 Batch  251/538, Loss:  1.237\n",
      "Epoch   0 Batch  252/538, Loss:  1.468\n",
      "Epoch   0 Batch  253/538, Loss:  1.166\n",
      "Epoch   0 Batch  254/538, Loss:  1.136\n",
      "Epoch   0 Batch  255/538, Loss:  1.318\n",
      "Epoch   0 Batch  256/538, Loss:  1.295\n",
      "Epoch   0 Batch  257/538, Loss:  1.181\n",
      "Epoch   0 Batch  258/538, Loss:  1.313\n",
      "Epoch   0 Batch  259/538, Loss:  1.237\n",
      "Epoch   0 Batch  260/538, Loss:  1.205\n",
      "Epoch   0 Batch  261/538, Loss:  1.187\n",
      "Epoch   0 Batch  262/538, Loss:  1.213\n",
      "Epoch   0 Batch  263/538, Loss:  0.962\n",
      "Epoch   0 Batch  264/538, Loss:  1.392\n",
      "Epoch   0 Batch  265/538, Loss:  1.295\n",
      "Epoch   0 Batch  266/538, Loss:  1.212\n",
      "Epoch   0 Batch  267/538, Loss:  1.068\n",
      "Epoch   0 Batch  268/538, Loss:  1.091\n",
      "Epoch   0 Batch  269/538, Loss:  1.128\n",
      "Epoch   0 Batch  270/538, Loss:  1.223\n",
      "Epoch   0 Batch  271/538, Loss:  0.981\n",
      "Epoch   0 Batch  272/538, Loss:  1.135\n",
      "Epoch   0 Batch  273/538, Loss:  1.319\n",
      "Epoch   0 Batch  274/538, Loss:  1.186\n",
      "Epoch   0 Batch  275/538, Loss:  1.317\n",
      "Epoch   0 Batch  276/538, Loss:  1.096\n",
      "Epoch   0 Batch  277/538, Loss:  1.056\n",
      "Epoch   0 Batch  278/538, Loss:  1.124\n",
      "Epoch   0 Batch  279/538, Loss:  0.956\n",
      "Epoch   0 Batch  280/538, Loss:  1.119\n",
      "Epoch   0 Batch  281/538, Loss:  1.208\n",
      "Epoch   0 Batch  282/538, Loss:  0.993\n",
      "Epoch   0 Batch  283/538, Loss:  1.010\n",
      "Epoch   0 Batch  284/538, Loss:  1.201\n",
      "Epoch   0 Batch  285/538, Loss:  1.278\n",
      "Epoch   0 Batch  286/538, Loss:  0.932\n",
      "Epoch   0 Batch  287/538, Loss:  1.242\n",
      "Epoch   0 Batch  288/538, Loss:  1.113\n",
      "Epoch   0 Batch  289/538, Loss:  1.124\n",
      "Epoch   0 Batch  290/538, Loss:  1.022\n",
      "Epoch   0 Batch  291/538, Loss:  1.203\n",
      "Epoch   0 Batch  292/538, Loss:  1.023\n",
      "Epoch   0 Batch  293/538, Loss:  1.012\n",
      "Epoch   0 Batch  294/538, Loss:  1.104\n",
      "Epoch   0 Batch  295/538, Loss:  1.112\n",
      "Epoch   0 Batch  296/538, Loss:  0.997\n",
      "Epoch   0 Batch  297/538, Loss:  1.349\n",
      "Epoch   0 Batch  298/538, Loss:  1.058\n",
      "Epoch   0 Batch  299/538, Loss:  1.021\n",
      "Epoch   0 Batch  300/538, Loss:  0.946\n",
      "Epoch   0 Batch  301/538, Loss:  1.137\n",
      "Epoch   0 Batch  302/538, Loss:  1.108\n",
      "Epoch   0 Batch  303/538, Loss:  1.127\n",
      "Epoch   0 Batch  304/538, Loss:  1.134\n",
      "Epoch   0 Batch  305/538, Loss:  1.088\n",
      "Epoch   0 Batch  306/538, Loss:  0.794\n",
      "Epoch   0 Batch  307/538, Loss:  1.128\n",
      "Epoch   0 Batch  308/538, Loss:  1.057\n",
      "Epoch   0 Batch  309/538, Loss:  0.897\n",
      "Epoch   0 Batch  310/538, Loss:  0.842\n",
      "Epoch   0 Batch  311/538, Loss:  0.944\n",
      "Epoch   0 Batch  312/538, Loss:  0.948\n",
      "Epoch   0 Batch  313/538, Loss:  0.853\n",
      "Epoch   0 Batch  314/538, Loss:  1.048\n",
      "Epoch   0 Batch  315/538, Loss:  0.965\n",
      "Epoch   0 Batch  316/538, Loss:  0.784\n",
      "Epoch   0 Batch  317/538, Loss:  1.011\n",
      "Epoch   0 Batch  318/538, Loss:  0.972\n",
      "Epoch   0 Batch  319/538, Loss:  0.779\n",
      "Epoch   0 Batch  320/538, Loss:  1.023\n",
      "Epoch   0 Batch  321/538, Loss:  0.949\n",
      "Epoch   0 Batch  322/538, Loss:  0.929\n",
      "Epoch   0 Batch  323/538, Loss:  1.109\n",
      "Epoch   0 Batch  324/538, Loss:  0.804\n",
      "Epoch   0 Batch  325/538, Loss:  0.961\n",
      "Epoch   0 Batch  326/538, Loss:  0.942\n",
      "Epoch   0 Batch  327/538, Loss:  0.841\n",
      "Epoch   0 Batch  328/538, Loss:  1.012\n",
      "Epoch   0 Batch  329/538, Loss:  0.898\n",
      "Epoch   0 Batch  330/538, Loss:  0.889\n",
      "Epoch   0 Batch  331/538, Loss:  0.877\n",
      "Epoch   0 Batch  332/538, Loss:  1.018\n",
      "Epoch   0 Batch  333/538, Loss:  0.770\n",
      "Epoch   0 Batch  334/538, Loss:  0.922\n",
      "Epoch   0 Batch  335/538, Loss:  1.059\n",
      "Epoch   0 Batch  336/538, Loss:  0.944\n",
      "Epoch   0 Batch  337/538, Loss:  0.955\n",
      "Epoch   0 Batch  338/538, Loss:  0.944\n",
      "Epoch   0 Batch  339/538, Loss:  0.872\n",
      "Epoch   0 Batch  340/538, Loss:  0.776\n",
      "Epoch   0 Batch  341/538, Loss:  0.967\n",
      "Epoch   0 Batch  342/538, Loss:  0.886\n",
      "Epoch   0 Batch  343/538, Loss:  0.792\n",
      "Epoch   0 Batch  344/538, Loss:  0.836\n",
      "Epoch   0 Batch  345/538, Loss:  0.963\n",
      "Epoch   0 Batch  346/538, Loss:  1.161\n",
      "Epoch   0 Batch  347/538, Loss:  0.996\n",
      "Epoch   0 Batch  348/538, Loss:  0.776\n",
      "Epoch   0 Batch  349/538, Loss:  0.747\n",
      "Epoch   0 Batch  350/538, Loss:  0.708\n",
      "Epoch   0 Batch  351/538, Loss:  0.933\n",
      "Epoch   0 Batch  352/538, Loss:  0.958\n",
      "Epoch   0 Batch  353/538, Loss:  1.227\n",
      "Epoch   0 Batch  354/538, Loss:  0.892\n",
      "Epoch   0 Batch  355/538, Loss:  0.906\n",
      "Epoch   0 Batch  356/538, Loss:  0.713\n",
      "Epoch   0 Batch  357/538, Loss:  0.799\n",
      "Epoch   0 Batch  358/538, Loss:  0.884\n",
      "Epoch   0 Batch  359/538, Loss:  0.785\n",
      "Epoch   0 Batch  360/538, Loss:  0.802\n",
      "Epoch   0 Batch  361/538, Loss:  0.939\n",
      "Epoch   0 Batch  362/538, Loss:  0.765\n",
      "Epoch   0 Batch  363/538, Loss:  0.770\n",
      "Epoch   0 Batch  364/538, Loss:  0.857\n",
      "Epoch   0 Batch  365/538, Loss:  1.026\n",
      "Epoch   0 Batch  366/538, Loss:  0.910\n",
      "Epoch   0 Batch  367/538, Loss:  0.711\n",
      "Epoch   0 Batch  368/538, Loss:  0.850\n",
      "Epoch   0 Batch  369/538, Loss:  0.908\n",
      "Epoch   0 Batch  370/538, Loss:  0.792\n",
      "Epoch   0 Batch  371/538, Loss:  0.876\n",
      "Epoch   0 Batch  372/538, Loss:  1.023\n",
      "Epoch   0 Batch  373/538, Loss:  0.979\n",
      "Epoch   0 Batch  374/538, Loss:  0.753\n",
      "Epoch   0 Batch  375/538, Loss:  0.823\n",
      "Epoch   0 Batch  376/538, Loss:  0.857\n",
      "Epoch   0 Batch  377/538, Loss:  0.826\n",
      "Epoch   0 Batch  378/538, Loss:  0.844\n",
      "Epoch   0 Batch  379/538, Loss:  0.847\n",
      "Epoch   0 Batch  380/538, Loss:  0.963\n",
      "Epoch   0 Batch  381/538, Loss:  0.886\n",
      "Epoch   0 Batch  382/538, Loss:  0.962\n",
      "Epoch   0 Batch  383/538, Loss:  0.803\n",
      "Epoch   0 Batch  384/538, Loss:  0.894\n",
      "Epoch   0 Batch  385/538, Loss:  0.967\n",
      "Epoch   0 Batch  386/538, Loss:  0.938\n",
      "Epoch   0 Batch  387/538, Loss:  0.853\n",
      "Epoch   0 Batch  388/538, Loss:  0.859\n",
      "Epoch   0 Batch  389/538, Loss:  0.854\n",
      "Epoch   0 Batch  390/538, Loss:  0.929\n",
      "Epoch   0 Batch  391/538, Loss:  0.693\n",
      "Epoch   0 Batch  392/538, Loss:  0.802\n",
      "Epoch   0 Batch  393/538, Loss:  0.893\n",
      "Epoch   0 Batch  394/538, Loss:  0.759\n",
      "Epoch   0 Batch  395/538, Loss:  0.797\n",
      "Epoch   0 Batch  396/538, Loss:  1.008\n",
      "Epoch   0 Batch  397/538, Loss:  0.851\n",
      "Epoch   0 Batch  398/538, Loss:  0.871\n",
      "Epoch   0 Batch  399/538, Loss:  0.735\n",
      "Epoch   0 Batch  400/538, Loss:  0.910\n",
      "Epoch   0 Batch  401/538, Loss:  0.774\n",
      "Epoch   0 Batch  402/538, Loss:  0.884\n",
      "Epoch   0 Batch  403/538, Loss:  0.780\n",
      "Epoch   0 Batch  404/538, Loss:  0.909\n",
      "Epoch   0 Batch  405/538, Loss:  0.764\n",
      "Epoch   0 Batch  406/538, Loss:  0.943\n",
      "Epoch   0 Batch  407/538, Loss:  0.976\n",
      "Epoch   0 Batch  408/538, Loss:  0.849\n",
      "Epoch   0 Batch  409/538, Loss:  0.722\n",
      "Epoch   0 Batch  410/538, Loss:  0.834\n",
      "Epoch   0 Batch  411/538, Loss:  0.876\n",
      "Epoch   0 Batch  412/538, Loss:  0.811\n",
      "Epoch   0 Batch  413/538, Loss:  0.841\n",
      "Epoch   0 Batch  414/538, Loss:  0.893\n",
      "Epoch   0 Batch  415/538, Loss:  0.924\n",
      "Epoch   0 Batch  416/538, Loss:  0.771\n",
      "Epoch   0 Batch  417/538, Loss:  0.882\n",
      "Epoch   0 Batch  418/538, Loss:  0.823\n",
      "Epoch   0 Batch  419/538, Loss:  0.790\n",
      "Epoch   0 Batch  420/538, Loss:  0.620\n",
      "Epoch   0 Batch  421/538, Loss:  0.642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch  422/538, Loss:  0.712\n",
      "Epoch   0 Batch  423/538, Loss:  0.883\n",
      "Epoch   0 Batch  424/538, Loss:  0.756\n",
      "Epoch   0 Batch  425/538, Loss:  0.862\n",
      "Epoch   0 Batch  426/538, Loss:  0.822\n",
      "Epoch   0 Batch  427/538, Loss:  0.873\n",
      "Epoch   0 Batch  428/538, Loss:  0.791\n",
      "Epoch   0 Batch  429/538, Loss:  0.808\n",
      "Epoch   0 Batch  430/538, Loss:  0.900\n",
      "Epoch   0 Batch  431/538, Loss:  0.684\n",
      "Epoch   0 Batch  432/538, Loss:  0.795\n",
      "Epoch   0 Batch  433/538, Loss:  0.736\n",
      "Epoch   0 Batch  434/538, Loss:  0.859\n",
      "Epoch   0 Batch  435/538, Loss:  0.725\n",
      "Epoch   0 Batch  436/538, Loss:  0.670\n",
      "Epoch   0 Batch  437/538, Loss:  0.758\n",
      "Epoch   0 Batch  438/538, Loss:  0.707\n",
      "Epoch   0 Batch  439/538, Loss:  0.847\n",
      "Epoch   0 Batch  440/538, Loss:  0.773\n",
      "Epoch   0 Batch  441/538, Loss:  0.723\n",
      "Epoch   0 Batch  442/538, Loss:  0.779\n",
      "Epoch   0 Batch  443/538, Loss:  0.762\n",
      "Epoch   0 Batch  444/538, Loss:  0.801\n",
      "Epoch   0 Batch  445/538, Loss:  0.641\n",
      "Epoch   0 Batch  446/538, Loss:  0.772\n",
      "Epoch   0 Batch  447/538, Loss:  0.766\n",
      "Epoch   0 Batch  448/538, Loss:  0.778\n",
      "Epoch   0 Batch  449/538, Loss:  0.576\n",
      "Epoch   0 Batch  450/538, Loss:  0.829\n",
      "Epoch   0 Batch  451/538, Loss:  0.765\n",
      "Epoch   0 Batch  452/538, Loss:  0.689\n",
      "Epoch   0 Batch  453/538, Loss:  0.785\n",
      "Epoch   0 Batch  454/538, Loss:  0.752\n",
      "Epoch   0 Batch  455/538, Loss:  0.878\n",
      "Epoch   0 Batch  456/538, Loss:  0.772\n",
      "Epoch   0 Batch  457/538, Loss:  0.916\n",
      "Epoch   0 Batch  458/538, Loss:  0.634\n",
      "Epoch   0 Batch  459/538, Loss:  0.706\n",
      "Epoch   0 Batch  460/538, Loss:  0.669\n",
      "Epoch   0 Batch  461/538, Loss:  0.788\n",
      "Epoch   0 Batch  462/538, Loss:  1.050\n",
      "Epoch   0 Batch  463/538, Loss:  0.868\n",
      "Epoch   0 Batch  464/538, Loss:  0.718\n",
      "Epoch   0 Batch  465/538, Loss:  0.707\n",
      "Epoch   0 Batch  466/538, Loss:  0.908\n",
      "Epoch   0 Batch  467/538, Loss:  0.813\n",
      "Epoch   0 Batch  468/538, Loss:  0.701\n",
      "Epoch   0 Batch  469/538, Loss:  0.847\n",
      "Epoch   0 Batch  470/538, Loss:  0.886\n",
      "Epoch   0 Batch  471/538, Loss:  0.693\n",
      "Epoch   0 Batch  472/538, Loss:  0.815\n",
      "Epoch   0 Batch  473/538, Loss:  0.657\n",
      "Epoch   0 Batch  474/538, Loss:  0.922\n",
      "Epoch   0 Batch  475/538, Loss:  0.800\n",
      "Epoch   0 Batch  476/538, Loss:  0.708\n",
      "Epoch   0 Batch  477/538, Loss:  0.676\n",
      "Epoch   0 Batch  478/538, Loss:  0.766\n",
      "Epoch   0 Batch  479/538, Loss:  0.770\n",
      "Epoch   0 Batch  480/538, Loss:  0.801\n",
      "Epoch   0 Batch  481/538, Loss:  0.640\n",
      "Epoch   0 Batch  482/538, Loss:  0.665\n",
      "Epoch   0 Batch  483/538, Loss:  0.693\n",
      "Epoch   0 Batch  484/538, Loss:  0.804\n",
      "Epoch   0 Batch  485/538, Loss:  0.785\n",
      "Epoch   0 Batch  486/538, Loss:  0.744\n",
      "Epoch   0 Batch  487/538, Loss:  0.557\n",
      "Epoch   0 Batch  488/538, Loss:  0.708\n",
      "Epoch   0 Batch  489/538, Loss:  0.736\n",
      "Epoch   0 Batch  490/538, Loss:  0.742\n",
      "Epoch   0 Batch  491/538, Loss:  0.685\n",
      "Epoch   0 Batch  492/538, Loss:  0.838\n",
      "Epoch   0 Batch  493/538, Loss:  0.649\n",
      "Epoch   0 Batch  494/538, Loss:  0.746\n",
      "Epoch   0 Batch  495/538, Loss:  0.737\n",
      "Epoch   0 Batch  496/538, Loss:  0.661\n",
      "Epoch   0 Batch  497/538, Loss:  0.729\n",
      "Epoch   0 Batch  498/538, Loss:  0.791\n",
      "Epoch   0 Batch  499/538, Loss:  0.596\n",
      "Epoch   0 Batch  500/538, Loss:  0.777\n",
      "Epoch   0 Batch  501/538, Loss:  0.698\n",
      "Epoch   0 Batch  502/538, Loss:  0.767\n",
      "Epoch   0 Batch  503/538, Loss:  0.608\n",
      "Epoch   0 Batch  504/538, Loss:  0.690\n",
      "Epoch   0 Batch  505/538, Loss:  0.617\n",
      "Epoch   0 Batch  506/538, Loss:  0.663\n",
      "Epoch   0 Batch  507/538, Loss:  0.696\n",
      "Epoch   0 Batch  508/538, Loss:  0.821\n",
      "Epoch   0 Batch  509/538, Loss:  0.711\n",
      "Epoch   0 Batch  510/538, Loss:  0.777\n",
      "Epoch   0 Batch  511/538, Loss:  0.701\n",
      "Epoch   0 Batch  512/538, Loss:  0.703\n",
      "Epoch   0 Batch  513/538, Loss:  0.889\n",
      "Epoch   0 Batch  514/538, Loss:  0.591\n",
      "Epoch   0 Batch  515/538, Loss:  0.758\n",
      "Epoch   0 Batch  516/538, Loss:  0.728\n",
      "Epoch   0 Batch  517/538, Loss:  0.806\n",
      "Epoch   0 Batch  518/538, Loss:  0.635\n",
      "Epoch   0 Batch  519/538, Loss:  0.718\n",
      "Epoch   0 Batch  520/538, Loss:  0.681\n",
      "Epoch   0 Batch  521/538, Loss:  0.650\n",
      "Epoch   0 Batch  522/538, Loss:  0.850\n",
      "Epoch   0 Batch  523/538, Loss:  0.564\n",
      "Epoch   0 Batch  524/538, Loss:  0.606\n",
      "Epoch   0 Batch  525/538, Loss:  0.717\n",
      "Epoch   0 Batch  526/538, Loss:  0.644\n",
      "Epoch   0 Batch  527/538, Loss:  0.744\n",
      "Epoch   0 Batch  528/538, Loss:  0.728\n",
      "Epoch   0 Batch  529/538, Loss:  0.680\n",
      "Epoch   0 Batch  530/538, Loss:  0.615\n",
      "Epoch   0 Batch  531/538, Loss:  0.667\n",
      "Epoch   0 Batch  532/538, Loss:  0.629\n",
      "Epoch   0 Batch  533/538, Loss:  0.655\n",
      "Epoch   0 Batch  534/538, Loss:  0.729\n",
      "Epoch   0 Batch  535/538, Loss:  0.640\n",
      "Epoch   0 Batch  536/538, Loss:  0.623\n",
      "Epoch   0 Batch  537/538, Loss:  0.568\n",
      "Training time:  0.15765047073364258\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Failed to rename: checkpoints/dev.data-00000-of-00001.tempstate1783762023044192084 to: checkpoints/dev.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable/_387, Variable/Adam/_389, Variable/Adam_1/_391, Variable_1/_393, Variable_1/Adam/_395, Variable_1/Adam_1/_397, beta1_power/_399, beta2_power/_401, decoder/attention/attention_layer/kernel/_403, decoder/attention/attention_layer/kernel/Adam/_405, decoder/attention/attention_layer/kernel/Adam_1/_407, decoder/attention/bahdanau_attention/attention_b/_409, decoder/attention/bahdanau_attention/attention_b/Adam/_411, decoder/attention/bahdanau_attention/attention_b/Adam_1/_413, decoder/attention/bahdanau_attention/attention_g/_415, decoder/attention/bahdanau_attention/attention_g/Adam/_417, decoder/attention/bahdanau_attention/attention_g/Adam_1/_419, decoder/attention/bahdanau_attention/attention_v/_421, decoder/attention/bahdanau_attention/attention_v/Adam/_423, decoder/attention/bahdanau_attention/attention_v/Adam_1/_425, decoder/attention/bahdanau_attention/query_layer/kernel/_427, decoder/attention/bahdanau_attention/query_layer/kernel/Adam/_429, decoder/attention/bahdanau_attention/query_layer/kernel/Adam_1/_431, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/_433, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam/_435, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam_1/_437, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/_439, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam/_441, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1/_443, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/_445, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam/_447, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1/_449, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/_451, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam/_453, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1/_455, decoder_1/attention_infer/attention_layer/kernel/_457, decoder_1/attention_infer/bahdanau_attention/attention_b/_459, decoder_1/attention_infer/bahdanau_attention/attention_g/_461, decoder_1/attention_infer/bahdanau_attention/attention_v/_463, decoder_1/attention_infer/bahdanau_attention/query_layer/kernel/_465, memory_layer/kernel/_467, memory_layer/kernel/Adam/_469, memory_layer/kernel/Adam_1/_471, memory_layer_1/kernel/_473, output_projection/bias/_475, output_projection/bias/Adam/_477, output_projection/bias/Adam_1/_479, output_projection/kernel/_481, output_projection/kernel/Adam/_483, output_projection/kernel/Adam_1/_485, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/_487, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam/_489, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam_1/_491, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/_493, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam/_495, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1/_497, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/_499, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam/_501, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1/_503, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/_505, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam/_507, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1/_509)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-c1c4b6392ebb>\", line 58, in <module>\n    saver = tf.train.Saver()\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1218, in __init__\n    self.build()\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 748, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 296, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 239, in save_op\n    tensors)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1162, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Failed to rename: checkpoints/dev.data-00000-of-00001.tempstate1783762023044192084 to: checkpoints/dev.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable/_387, Variable/Adam/_389, Variable/Adam_1/_391, Variable_1/_393, Variable_1/Adam/_395, Variable_1/Adam_1/_397, beta1_power/_399, beta2_power/_401, decoder/attention/attention_layer/kernel/_403, decoder/attention/attention_layer/kernel/Adam/_405, decoder/attention/attention_layer/kernel/Adam_1/_407, decoder/attention/bahdanau_attention/attention_b/_409, decoder/attention/bahdanau_attention/attention_b/Adam/_411, decoder/attention/bahdanau_attention/attention_b/Adam_1/_413, decoder/attention/bahdanau_attention/attention_g/_415, decoder/attention/bahdanau_attention/attention_g/Adam/_417, decoder/attention/bahdanau_attention/attention_g/Adam_1/_419, decoder/attention/bahdanau_attention/attention_v/_421, decoder/attention/bahdanau_attention/attention_v/Adam/_423, decoder/attention/bahdanau_attention/attention_v/Adam_1/_425, decoder/attention/bahdanau_attention/query_layer/kernel/_427, decoder/attention/bahdanau_attention/query_layer/kernel/Adam/_429, decoder/attention/bahdanau_attention/query_layer/kernel/Adam_1/_431, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/_433, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam/_435, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam_1/_437, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/_439, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam/_441, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1/_443, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/_445, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam/_447, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1/_449, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/_451, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam/_453, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1/_455, decoder_1/attention_infer/attention_layer/kernel/_457, decoder_1/attention_infer/bahdanau_attention/attention_b/_459, decoder_1/attention_infer/bahdanau_attention/attention_g/_461, decoder_1/attention_infer/bahdanau_attention/attention_v/_463, decoder_1/attention_infer/bahdanau_attention/query_layer/kernel/_465, memory_layer/kernel/_467, memory_layer/kernel/Adam/_469, memory_layer/kernel/Adam_1/_471, memory_layer_1/kernel/_473, output_projection/bias/_475, output_projection/bias/Adam/_477, output_projection/bias/Adam_1/_479, output_projection/kernel/_481, output_projection/kernel/Adam/_483, output_projection/kernel/Adam_1/_485, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/_487, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam/_489, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam_1/_491, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/_493, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam/_495, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1/_497, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/_499, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam/_501, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1/_503, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/_505, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam/_507, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1/_509)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Failed to rename: checkpoints/dev.data-00000-of-00001.tempstate1783762023044192084 to: checkpoints/dev.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable/_387, Variable/Adam/_389, Variable/Adam_1/_391, Variable_1/_393, Variable_1/Adam/_395, Variable_1/Adam_1/_397, beta1_power/_399, beta2_power/_401, decoder/attention/attention_layer/kernel/_403, decoder/attention/attention_layer/kernel/Adam/_405, decoder/attention/attention_layer/kernel/Adam_1/_407, decoder/attention/bahdanau_attention/attention_b/_409, decoder/attention/bahdanau_attention/attention_b/Adam/_411, decoder/attention/bahdanau_attention/attention_b/Adam_1/_413, decoder/attention/bahdanau_attention/attention_g/_415, decoder/attention/bahdanau_attention/attention_g/Adam/_417, decoder/attention/bahdanau_attention/attention_g/Adam_1/_419, decoder/attention/bahdanau_attention/attention_v/_421, decoder/attention/bahdanau_attention/attention_v/Adam/_423, decoder/attention/bahdanau_attention/attention_v/Adam_1/_425, decoder/attention/bahdanau_attention/query_layer/kernel/_427, decoder/attention/bahdanau_attention/query_layer/kernel/Adam/_429, decoder/attention/bahdanau_attention/query_layer/kernel/Adam_1/_431, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/_433, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam/_435, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam_1/_437, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/_439, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam/_441, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1/_443, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/_445, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam/_447, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1/_449, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/_451, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam/_453, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1/_455, decoder_1/attention_infer/attention_layer/kernel/_457, decoder_1/attention_infer/bahdanau_attention/attention_b/_459, decoder_1/attention_infer/bahdanau_attention/attention_g/_461, decoder_1/attention_infer/bahdanau_attention/attention_v/_463, decoder_1/attention_infer/bahdanau_attention/query_layer/kernel/_465, memory_layer/kernel/_467, memory_layer/kernel/Adam/_469, memory_layer/kernel/Adam_1/_471, memory_layer_1/kernel/_473, output_projection/bias/_475, output_projection/bias/Adam/_477, output_projection/bias/Adam_1/_479, output_projection/kernel/_481, output_projection/kernel/Adam/_483, output_projection/kernel/Adam_1/_485, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/_487, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam/_489, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam_1/_491, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/_493, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam/_495, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1/_497, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/_499, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam/_501, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1/_503, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/_505, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam/_507, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1/_509)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c1c4b6392ebb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# Save Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model Trained and Saved'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[0;32m   1592\u001b[0m               \"Parent directory of {} doesn't exist, can't save.\".format(\n\u001b[0;32m   1593\u001b[0m                   save_path))\n\u001b[1;32m-> 1594\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1596\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[0;32m   1571\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[0;32m   1572\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1573\u001b[1;33m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[0;32m   1574\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1575\u001b[0m           self._build_eager(\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Failed to rename: checkpoints/dev.data-00000-of-00001.tempstate1783762023044192084 to: checkpoints/dev.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable/_387, Variable/Adam/_389, Variable/Adam_1/_391, Variable_1/_393, Variable_1/Adam/_395, Variable_1/Adam_1/_397, beta1_power/_399, beta2_power/_401, decoder/attention/attention_layer/kernel/_403, decoder/attention/attention_layer/kernel/Adam/_405, decoder/attention/attention_layer/kernel/Adam_1/_407, decoder/attention/bahdanau_attention/attention_b/_409, decoder/attention/bahdanau_attention/attention_b/Adam/_411, decoder/attention/bahdanau_attention/attention_b/Adam_1/_413, decoder/attention/bahdanau_attention/attention_g/_415, decoder/attention/bahdanau_attention/attention_g/Adam/_417, decoder/attention/bahdanau_attention/attention_g/Adam_1/_419, decoder/attention/bahdanau_attention/attention_v/_421, decoder/attention/bahdanau_attention/attention_v/Adam/_423, decoder/attention/bahdanau_attention/attention_v/Adam_1/_425, decoder/attention/bahdanau_attention/query_layer/kernel/_427, decoder/attention/bahdanau_attention/query_layer/kernel/Adam/_429, decoder/attention/bahdanau_attention/query_layer/kernel/Adam_1/_431, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/_433, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam/_435, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam_1/_437, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/_439, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam/_441, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1/_443, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/_445, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam/_447, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1/_449, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/_451, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam/_453, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1/_455, decoder_1/attention_infer/attention_layer/kernel/_457, decoder_1/attention_infer/bahdanau_attention/attention_b/_459, decoder_1/attention_infer/bahdanau_attention/attention_g/_461, decoder_1/attention_infer/bahdanau_attention/attention_v/_463, decoder_1/attention_infer/bahdanau_attention/query_layer/kernel/_465, memory_layer/kernel/_467, memory_layer/kernel/Adam/_469, memory_layer/kernel/Adam_1/_471, memory_layer_1/kernel/_473, output_projection/bias/_475, output_projection/bias/Adam/_477, output_projection/bias/Adam_1/_479, output_projection/kernel/_481, output_projection/kernel/Adam/_483, output_projection/kernel/Adam_1/_485, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/_487, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam/_489, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam_1/_491, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/_493, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam/_495, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1/_497, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/_499, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam/_501, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1/_503, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/_505, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam/_507, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1/_509)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-c1c4b6392ebb>\", line 58, in <module>\n    saver = tf.train.Saver()\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1218, in __init__\n    self.build()\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 748, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 296, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 239, in save_op\n    tensors)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1162, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Failed to rename: checkpoints/dev.data-00000-of-00001.tempstate1783762023044192084 to: checkpoints/dev.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable/_387, Variable/Adam/_389, Variable/Adam_1/_391, Variable_1/_393, Variable_1/Adam/_395, Variable_1/Adam_1/_397, beta1_power/_399, beta2_power/_401, decoder/attention/attention_layer/kernel/_403, decoder/attention/attention_layer/kernel/Adam/_405, decoder/attention/attention_layer/kernel/Adam_1/_407, decoder/attention/bahdanau_attention/attention_b/_409, decoder/attention/bahdanau_attention/attention_b/Adam/_411, decoder/attention/bahdanau_attention/attention_b/Adam_1/_413, decoder/attention/bahdanau_attention/attention_g/_415, decoder/attention/bahdanau_attention/attention_g/Adam/_417, decoder/attention/bahdanau_attention/attention_g/Adam_1/_419, decoder/attention/bahdanau_attention/attention_v/_421, decoder/attention/bahdanau_attention/attention_v/Adam/_423, decoder/attention/bahdanau_attention/attention_v/Adam_1/_425, decoder/attention/bahdanau_attention/query_layer/kernel/_427, decoder/attention/bahdanau_attention/query_layer/kernel/Adam/_429, decoder/attention/bahdanau_attention/query_layer/kernel/Adam_1/_431, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/_433, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam/_435, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam_1/_437, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/_439, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam/_441, decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1/_443, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/_445, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam/_447, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1/_449, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/_451, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam/_453, decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1/_455, decoder_1/attention_infer/attention_layer/kernel/_457, decoder_1/attention_infer/bahdanau_attention/attention_b/_459, decoder_1/attention_infer/bahdanau_attention/attention_g/_461, decoder_1/attention_infer/bahdanau_attention/attention_v/_463, decoder_1/attention_infer/bahdanau_attention/query_layer/kernel/_465, memory_layer/kernel/_467, memory_layer/kernel/Adam/_469, memory_layer/kernel/Adam_1/_471, memory_layer_1/kernel/_473, output_projection/bias/_475, output_projection/bias/Adam/_477, output_projection/bias/Adam_1/_479, output_projection/kernel/_481, output_projection/kernel/Adam/_483, output_projection/kernel/Adam_1/_485, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/_487, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam/_489, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam_1/_491, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/_493, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam/_495, rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1/_497, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/_499, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam/_501, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1/_503, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/_505, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam/_507, rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1/_509)]]\n"
     ]
    }
   ],
   "source": [
    "def sentence_to_seq(sentence, vocab_to_int):\n",
    "    \"\"\"\n",
    "    Convert a sentence to a sequence of ids\n",
    "    :param sentence: String\n",
    "    :param vocab_to_int: Dictionary to go from the words to an id\n",
    "    :return: List of word ids\n",
    "    \"\"\"\n",
    "    lower_case_words = [word.lower() for word in sentence.split()]\n",
    "    \n",
    "    word_id = [vocab_to_int.get(word, vocab_to_int['<unk>']) for word in lower_case_words]\n",
    "    \n",
    "    return word_id\n",
    "\n",
    "import time\n",
    "\n",
    "### TRAINING ###\n",
    "save_path = 'checkpoints/dev'\n",
    "\n",
    "train_source = source_int_text[:]\n",
    "train_target = target_int_text[:]\n",
    "\n",
    "valid_source = source_int_text[:train_hparams.batch_size]\n",
    "valid_target = target_int_text[:train_hparams.batch_size]\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch_i in range(train_hparams.epochs):\n",
    "        for batch_i, (source_batch, target_batch) in enumerate(\n",
    "                batch_data(train_source, train_target, train_hparams.batch_size)):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            source_batch_seq_lenght = []\n",
    "            for item in source_batch:\n",
    "                source_batch_seq_lenght.append(np.shape(item)[0])\n",
    "            \n",
    "            target_batch_seq_lenght = []\n",
    "            for item in target_batch:\n",
    "                target_batch_seq_lenght.append(np.shape(item)[0])\n",
    "                \n",
    "#             if (source_batch_seq_lenght[0] > 300):\n",
    "#                 continue\n",
    "                \n",
    "            _, loss_val = sess.run(\n",
    "                [updates, loss],\n",
    "                {encoder_inputs: source_batch,\n",
    "                 decoder_inputs: target_batch,\n",
    "                encoder_inputs_length: source_batch_seq_lenght,\n",
    "                decoder_inputs_length: target_batch_seq_lenght})\n",
    "\n",
    "            print('Epoch {:>3} Batch {:>4}/{}, Loss: {:>6.3f}'\n",
    "                  .format(epoch_i, batch_i, len(source_int_text) // train_hparams.batch_size, loss_val))\n",
    "            \n",
    "            end_time = time.time()\n",
    "            \n",
    "    print(\"Training time: \", end_time - start_time)\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_path)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save parameters for checkpoint\n",
    "save_params(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "_, (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab, target_int_to_vocab) = load_preprocess()\n",
    "load_path = load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "(16,)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "File checkpoints/dev.meta does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-9ceb3d78b527>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloaded_graph\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Load saved model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.meta'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mimport_meta_graph\u001b[1;34m(meta_graph_or_file, clear_devices, import_scope, **kwargs)\u001b[0m\n\u001b[0;32m   1801\u001b[0m                      \"execution is enabled.\")\n\u001b[0;32m   1802\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_graph_or_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_graph_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMetaGraphDef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1803\u001b[1;33m     \u001b[0mmeta_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_meta_graph_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_graph_or_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1804\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1805\u001b[0m     \u001b[0mmeta_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_or_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\u001b[0m in \u001b[0;36mread_meta_graph_file\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    553\u001b[0m   \u001b[0mmeta_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMetaGraphDef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"File %s does not exist.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m   \u001b[1;31m# First try to read it as a binary file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m   \u001b[0mfile_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: File checkpoints/dev.meta does not exist."
     ]
    }
   ],
   "source": [
    "translate_sentence = \"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"\n",
    "#fr to en\n",
    "#input: \"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"\n",
    "#target:\"new jersey is sometimes quiet during autumn , and it is snowy in april .\"\n",
    "\n",
    "#en to vi\n",
    "#input:  \"H vit gn 1000 trang v ch  ny .\"\n",
    "#target: \"They wrote almost a thousand pages on the topic .\"\n",
    "\n",
    "print(translate_sentence)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "translate_sentence = sentence_to_seq(translate_sentence, source_vocab_to_int)\n",
    "print(np.shape(translate_sentence))\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_path + '.meta')\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    encoder_inputs = loaded_graph.get_tensor_by_name('encoder_inputs:0')\n",
    "    encoder_inputs_length = loaded_graph.get_tensor_by_name('encoder_inputs_length:0')\n",
    "    decoder_pred_decode = loaded_graph.get_tensor_by_name('decoder_pred_decode:0')\n",
    "    \n",
    "    predicted_ids = sess.run(decoder_pred_decode, {encoder_inputs: [translate_sentence],\n",
    "                                                       encoder_inputs_length: [np.shape(translate_sentence)[0]]})[0]\n",
    "\n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_sentence]))\n",
    "print('  Source Words: {}'.format([source_int_to_vocab[i] for i in translate_sentence]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i[0] for i in predicted_ids]))\n",
    "print('  Predicted Words: {}'.format([target_int_to_vocab[i[0]] for i in predicted_ids]))\n",
    "\n",
    "print('\\nTranslation:\\n')\n",
    "translation = ''\n",
    "for word_i in translate_logits:\n",
    "    translation += target_int_to_vocab[word_i[0]] + ' '\n",
    "    \n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
